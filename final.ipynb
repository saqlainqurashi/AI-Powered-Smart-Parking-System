{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75d8f001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from numpy import cos, sin\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92e44832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvzone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b606bdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread('Capture.png')\n",
    "img=cv2.resize(img,((1200,600)))\n",
    "cv2.rectangle(img,(460,250),(650,500),(255,0,255),2)\n",
    "cv2.imshow('image',img)\n",
    "cv2.setMouseCallback('image',mouseClick)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68978e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "video1=cv2.VideoCapture('img-9906_uWwh6OdD.MOV')\n",
    "import cv2\n",
    "img=cv2.imread('Capture.png')\n",
    "img=cv2.resize(img,(1200,600))\n",
    "cv2.line(img, (310, 223), (207, 401), (255,0,255),2)\n",
    "cv2.line(img, (207, 401), (407, 402), (255,0,255),2)\n",
    "cv2.line(img, (407, 402), (446, 222), (255,0,255),2)\n",
    "cv2.line(img, (446, 222), (310, 223), (255,0,255),2)\n",
    "\n",
    "cv2.line(img, (483, 219), (449, 404), (255,0,255),2)\n",
    "cv2.line(img, (449, 404),(658,408), (255,0,255),2)\n",
    "cv2.line(img, (658,408), (626, 225), (255,0,255),2)\n",
    "cv2.line(img, (626, 225), (483, 219), (255,0,255),2)\n",
    "cv2.imshow(\"image\",img)\n",
    "# cv2.setMouseCallback('image',mouseClick)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "# print(poslist)\n",
    "while(video1.isOpened()):\n",
    "    ret,frame2 = video1.read()\n",
    "    image2=cv2.resize(frame2,(1200,600))\n",
    "    add = cv2.addWeighted(image2, 0.8, img, 0.3, 0)\n",
    "    cv2.imshow('Frame', add)\n",
    "    if cv2.waitKey(25) & 0xFF == ord('y'):\n",
    "        break\n",
    "    \n",
    "video1.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a769cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread('Capture.png')\n",
    "img=cv2.resize(img,((1200,600)))\n",
    "\n",
    "width, height =190,250\n",
    "poslist=[(465, 210)]\n",
    "\n",
    "def mouseClick(events,x,y,flags,params):\n",
    "    if events==cv2.EVENT_LBUTTONDOWN:\n",
    "        poslist.append((x,y))\n",
    "\n",
    "# def rotated_rectangle(image, pos, (pos[0]+width,pos[1]+height), color, thickness, rotation=0):\n",
    "    \n",
    "#     angle = np.radians(rotation)\n",
    "        \n",
    "for pos in poslist:\n",
    "    rot_rectangle=cv2.rectangle(img,pos,(pos[0]+width,pos[1]+height),(255,0,255),2)\n",
    "    print(pos)\n",
    "\n",
    "cv2.imshow('image',img)\n",
    "cv2.setMouseCallback('image',mouseClick)\n",
    "cv2.waitKey(10)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9851647d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "(149, 209), (308, 219), (472, 219), (654, 218), (845, 226)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2002bf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread('Capture.png')\n",
    "img=cv2.resize(img,((1200,600)))\n",
    "\n",
    "width, height =190,250\n",
    "poslist=[]\n",
    "\n",
    "def mouseClick(events,x,y,flags,params):\n",
    "    if events==cv2.EVENT_LBUTTONDOWN:\n",
    "        poslist.append((x,y))\n",
    "\n",
    "# def rotated_rectangle(image, pos, (pos[0]+width,pos[1]+height), color, thickness, rotation=0):\n",
    "    \n",
    "#     angle = np.radians(rotation)\n",
    "        \n",
    "for pos in poslist:\n",
    "    cv2.rectangle(img,pos,(pos[0]+width,pos[1]+height),(255,0,255),2)\n",
    "#     cv2.line(image, 465, 210, (255,0,255),2) \n",
    "#     print(pos)\n",
    "\n",
    "cv2.imshow(\"Rotated Rectangle\",rectangle)\n",
    "cv2.setMouseCallback('image',mouseClick)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "578e2500",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread('Capture.png')\n",
    "img=cv2.resize(img,((1200,600)))\n",
    "cv2.line(img, (465, 210),(465+190,210+250), (255,0,255),2)\n",
    "cv2.imshow(\"Rotated Rectangle\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7c49ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img=cv2.imread('Capture.png')\n",
    "img=cv2.resize(img,((1200,600)))\n",
    "\n",
    "width, height =190,250\n",
    "poslist=[]\n",
    "\n",
    "def mouseClick(events,x,y,flags,params):\n",
    "    if events==cv2.EVENT_LBUTTONDOWN:\n",
    "        poslist.append((x,y))\n",
    "\n",
    "# def rotated_rectangle(image, pos, (pos[0]+width,pos[1]+height), color, thickness, rotation=0):\n",
    "    \n",
    "#     angle = np.radians(rotation)\n",
    "        \n",
    "for pos in poslist:\n",
    "    cv2.rectangle(img,pos,(pos[0]+width,pos[1]+height),(255,0,255),2)\n",
    "#     cv2.line(image, 465, 210, (255,0,255),2) \n",
    "#     print(pos)\n",
    "\n",
    "cv2.imshow(\"Rotated Rectangle\",rectangle)\n",
    "cv2.setMouseCallback('image',mouseClick)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbbccbf",
   "metadata": {},
   "source": [
    "# TASK 1 COORDINATES FINDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cae55ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from numpy import cos, sin\n",
    "import numpy as np\n",
    "import cvzone\n",
    "import easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fcc9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "video1=cv2.VideoCapture('img-9906_uWwh6OdD.MOV')\n",
    "while(video1.isOpened()):\n",
    "    ret,frame = video1.read()\n",
    "    image=cv2.resize(frame,(1200,600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "803662b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(378, 327), (376, 346), (413, 344), (412, 326)]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "img=cv2.imread('Capture.png')\n",
    "img=cv2.resize(img,((1200,600)))\n",
    "\n",
    "width, height =190,250\n",
    "poslist=[]\n",
    "\n",
    "def mouseClick(events,x,y,flags,params):\n",
    "    if events==cv2.EVENT_LBUTTONDOWN:\n",
    "        poslist.append((x,y))\n",
    "        \n",
    "for pos in poslist:\n",
    "#     cv2.rectangle(img,pos,(pos[0]+width,pos[1]+height),(255,0,255),2)\n",
    "    cv2.line(img, pos, pos, (255,0,255),2)\n",
    "#     print(pos)\n",
    "\n",
    "cv2.imshow(\"image\",img)\n",
    "cv2.setMouseCallback('image',mouseClick)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "print(poslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09e77c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(310, 223), (207, 401), (407, 402), (446, 222), (483, 219), (449, 404), (658, 408)\n",
    "(310, 223), (207, 401), (407, 402), (477, 204), (444, 397), (664, 403), (640, 203)\n",
    "(310, 223), (207, 401), (407, 402),(475, 209), (445, 396), (664, 398), (636, 203)\n",
    "cv2.line(img, (378, 327), (376, 346), (255,0,255),2)\n",
    "cv2.line(img, (376, 346), (413, 344), (255,0,255),2)\n",
    "cv2.line(img, (413, 344), (412, 326), (255,0,255),2)\n",
    "cv2.line(img, (412, 326), (378, 327), (255,0,255),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6cb062",
   "metadata": {},
   "source": [
    "# DRAWING THE RACTANGLES IN PARKING AREA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "358ee4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img=cv2.imread('Capture1.png')\n",
    "img=cv2.resize(img,((1200,600)))\n",
    "cv2.line(img, (310, 223), (207, 401), (255,0,255),2)\n",
    "cv2.line(img, (207, 401), (407, 402), (255,0,255),2)\n",
    "cv2.line(img, (407, 402), (446, 222), (255,0,255),2)\n",
    "cv2.line(img, (446, 222), (310, 223), (255,0,255),2)\n",
    "\n",
    "cv2.line(img, (475, 209), (445, 396), (255,0,255),2)\n",
    "cv2.line(img, (445, 396),(664, 398), (255,0,255),2)\n",
    "cv2.line(img, (664, 398), (636, 203), (255,0,255),2)\n",
    "cv2.line(img, (636, 203), (475, 209), (255,0,255),2)\n",
    "cv2.imshow(\"image\",img)\n",
    "# cv2.setMouseCallback('image',mouseClick)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "# print(poslist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8d0c21",
   "metadata": {},
   "source": [
    "# SLICING OF THE BLOCKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8b9300d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img=cv2.imread('Capture1.png')\n",
    "img=cv2.resize(img,((1200,600)))\n",
    "cv2.line(img, (310, 223), (207, 401), (255,0,255),2)\n",
    "cv2.line(img, (207, 401), (407, 402), (255,0,255),2)\n",
    "cv2.line(img, (407, 402), (446, 222), (255,0,255),2)\n",
    "cv2.line(img, (446, 222), (310, 223), (255,0,255),2)\n",
    "\n",
    "cv2.line(img, (477, 204), (444, 397), (255,0,255),2)\n",
    "cv2.line(img, (444, 397),(664, 403), (255,0,255),2)\n",
    "cv2.line(img, (664, 403), (640, 203), (255,0,255),2)\n",
    "cv2.line(img, (640, 203), (477, 204), (255,0,255),2)\n",
    "cv2.imshow(\"image\",img)\n",
    "# cv2.setMouseCallback('image',mouseClick)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "# print(poslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa8cf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image1=img[223:402,310:407]\n",
    "image1=cv2.resize(image1,(1200,600))\n",
    "cv2.imshow(\"image\",image1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "864dc1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "image2=img[204:403,477:650]\n",
    "image2=cv2.resize(image2,(500,500))\n",
    "cv2.imshow(\"image\",image2)\n",
    "# cv2.setMouseCallback('image',mouseClick)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb96e0a",
   "metadata": {},
   "source": [
    "# VIDEO DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2dcdae84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvzone\n",
    "import cv2\n",
    "import numpy as np\n",
    "video1=cv2.VideoCapture('img-9906_uWwh6OdD.MOV')\n",
    "cascade=cv2.CascadeClassifier('cascade1.xml')\n",
    "while(video1.isOpened()):\n",
    "    var=False\n",
    "    var1=False\n",
    "    ret,frame2 = video1.read()\n",
    "    image=cv2.resize(frame2,(1200,600))\n",
    "    imggray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    imgblur=cv2.GaussianBlur(imggray,(3,3),5)\n",
    "    imgthreshold=cv2.adaptiveThreshold(imgblur,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV,25,16)\n",
    "    imgMedian=cv2.medianBlur(imgthreshold,5)\n",
    "    image1=imgthreshold[223:402,310:407]\n",
    "    count=cv2.countNonZero(image1)\n",
    "    if count>3300:\n",
    "        color=(255,0,0)\n",
    "        thickness=2\n",
    "        cvzone.putTextRect(image,str('occupied'),(223,310),scale=1,thickness=2,offset=0)\n",
    "    elif count<400:\n",
    "        color=(0,255,0)\n",
    "        thickness=2\n",
    "        cvzone.putTextRect(image,str('vacant'),(223,310),scale=1,thickness=2,offset=0)\n",
    "    elif count>=1500 or count<=2500:\n",
    "        color=(0,0,255)\n",
    "        thickness=2\n",
    "        var=True\n",
    "        \n",
    "    image2=imgthreshold[215:390,477:600]\n",
    "    count2=cv2.countNonZero(image2)\n",
    "    if count2>3300:\n",
    "        color1=(255,0,0)\n",
    "        thickness=2\n",
    "        cvzone.putTextRect(image,str('occupied'),(477,215),scale=1,thickness=2,offset=0)\n",
    "    elif count2<400:\n",
    "        color1=(0,255,0)\n",
    "        thickness=2\n",
    "        cvzone.putTextRect(image,str('vacant'),(477,215),scale=1,thickness=2,offset=0)\n",
    "    elif count2>=1500 or count2<=2500:\n",
    "        color1=(0,0,255)\n",
    "        thickness=2\n",
    "        var1=True\n",
    "    if var==True and var1==True:\n",
    "        cvzone.putTextRect(image,str('wrong'),(477,215),scale=1,thickness=2,offset=0)\n",
    "        cvzone.putTextRect(image,str('wrong'),(223,310),scale=1,thickness=2,offset=0)\n",
    "        image = cv2.putText(image, 'LE 4377', (378,327), cv2.FONT_HERSHEY_COMPLEX, \n",
    "                   1, (255,0,0), 2, cv2.LINE_AA)\n",
    "        var!=var\n",
    "        var1!=var1\n",
    "        cv2.line(image, (378, 327), (376, 346), (255,0,255),2)\n",
    "        cv2.line(image, (376, 346), (413, 344), (255,0,255),2)\n",
    "        cv2.line(image, (413, 344), (412, 326), (255,0,255),2)\n",
    "        cv2.line(image, (412, 326), (378, 327), (255,0,255),2)\n",
    "\n",
    "    image3=imgthreshold[218:429,666:951]\n",
    "    count3=cv2.countNonZero(image3) \n",
    "#     image = cv2.putText(image, str(count3), (666,218), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2, cv2.LINE_AA)\n",
    "    if count3>3300:\n",
    "        color2=(255,0,0)\n",
    "        thickness=2\n",
    "        cvzone.putTextRect(image3,str('occupied'),(477,215),scale=1,thickness=2,offset=0)\n",
    "    elif count3<2000:\n",
    "        color2=(0,255,0)\n",
    "        thickness=2\n",
    "        cvzone.putTextRect(image,str('vacant'),(666,218),scale=1,thickness=2,offset=0)\n",
    "    elif count3>=1500 or count3<=2500:\n",
    "        color2=(0,0,255)\n",
    "        thickness=2\n",
    "        var2=True\n",
    "\n",
    "    cv2.line(image, (310, 223), (207, 401), color,thickness)\n",
    "    cv2.line(image, (207, 401), (407, 402), color,thickness)\n",
    "    cv2.line(image, (407, 402), (446, 222), color,thickness)\n",
    "    cv2.line(image, (446, 222), (310, 223), color,thickness)\n",
    "\n",
    "    \n",
    "    cv2.line(image, (477, 215), (444, 397), color1,thickness)\n",
    "    cv2.line(image, (444, 397),(664, 403), color1,thickness)\n",
    "    cv2.line(image, (664, 403), (620, 215), color1,thickness)\n",
    "    cv2.line(image, (620, 215), (477, 215), color1,thickness)\n",
    "    \n",
    "    \n",
    "    cv2.line(image, (675, 227), (715, 399), color2,thickness)\n",
    "    \n",
    "    cv2.line(image, (715, 399), (925, 403), color2,thickness)\n",
    "    cv2.line(image, (925, 403), (824, 225), color2,thickness)\n",
    "    cv2.line(image, (824, 225), (675, 227), color2,thickness)\n",
    "\n",
    "    \n",
    "#     ractangle on threshold image\n",
    "    cv2.line(imgthreshold, (310, 223), (207, 401), (255,0,255),2)\n",
    "    cv2.line(imgthreshold, (207, 401), (407, 402), (255,0,255),2)\n",
    "    cv2.line(imgthreshold, (407, 402), (446, 222), (255,0,255),2)\n",
    "    cv2.line(imgthreshold, (446, 222), (310, 223), (255,0,255),2)\n",
    "    \n",
    "    cv2.line(imgthreshold, (477, 215), (444, 397), (255,0,255),2)\n",
    "    cv2.line(imgthreshold, (444, 397),(664, 403), (255,0,255),2)\n",
    "    cv2.line(imgthreshold, (664, 403), (620, 215), (255,0,255),2)\n",
    "    cv2.line(imgthreshold, (620, 215), (477, 215), (255,0,255),2)\n",
    "    \n",
    "    cv2.line(imgthreshold, (675, 227), (715, 399), (255,0,255),2)\n",
    "    cv2.line(imgthreshold, (715, 399), (925, 403), (255,0,255),2)\n",
    "    cv2.line(imgthreshold, (925, 403), (824, 225), (255,0,255),2)\n",
    "    cv2.line(imgthreshold, (824, 225), (675, 227), (255,0,255),2)\n",
    "    \n",
    "#     median image\n",
    "    cv2.line(imgMedian, (310, 223), (207, 401), (255,0,255),2)\n",
    "    cv2.line(imgMedian, (207, 401), (407, 402), (255,0,255),2)\n",
    "    cv2.line(imgMedian, (407, 402), (446, 222), (255,0,255),2)\n",
    "    cv2.line(imgMedian, (446, 222), (310, 223), (255,0,255),2)\n",
    "    \n",
    "    cv2.line(imgMedian, (477, 215), (444, 397), (255,0,255),2)\n",
    "    cv2.line(imgMedian, (444, 397),(664, 403), (255,0,255),2)\n",
    "    cv2.line(imgMedian, (664, 403), (640, 215), (255,0,255),2)\n",
    "    cv2.line(imgMedian, (640, 215), (477, 215), (255,0,255),2)\n",
    "    \n",
    "    cv2.line(imgMedian, (675, 227), (715, 399), (255,0,255),2)\n",
    "    cv2.line(imgMedian, (925, 403), (824, 225), (255,0,255),2)\n",
    "    cv2.line(imgMedian, (824, 225), (675, 227), (255,0,255),2)\n",
    "\n",
    "\n",
    "    cv2.imshow('orignal', image)\n",
    "    cv2.imshow(str(215*477),image1)\n",
    "    cv2.imshow(str(223*310),image2)\n",
    "    cv2.imshow('threshold', imgthreshold)\n",
    "    cv2.imshow('medianimage',imgMedian)\n",
    "    if cv2.waitKey(30) & 0xFF == ord('y'):\n",
    "        break\n",
    "    \n",
    "video1.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f5e126",
   "metadata": {},
   "source": [
    "# Video Detection 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "17309314",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.3) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-q3d_8t8e\\opencv\\modules\\imgproc\\src\\resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-9239aadb9822>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#     capture the frames of video\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mframe2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvideo1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mimage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m600\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;31m#     image processing on frames\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.3) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-q3d_8t8e\\opencv\\modules\\imgproc\\src\\resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "import cvzone\n",
    "import cv2\n",
    "import numpy as np\n",
    "video1=cv2.VideoCapture('img-9906_uWwh6OdD.MOV')\n",
    "cascade=cv2.CascadeClassifier('cascade1_ALPR.xml')\n",
    "while(video1.isOpened()):\n",
    "    var=False\n",
    "    var1=False\n",
    "#     capture the frames of video\n",
    "    ret,frame2 = video1.read()\n",
    "    image=cv2.resize(frame2,(1200,600))\n",
    "#     image processing on frames\n",
    "\n",
    "    imggray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    imgblur=cv2.GaussianBlur(imggray,(3,3),5)\n",
    "    imgthreshold=cv2.adaptiveThreshold(imgblur,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV,25,16)\n",
    "    imgMedian=cv2.medianBlur(imgthreshold,5)\n",
    "#     slicing/croping the required area\n",
    "\n",
    "    image1=imgthreshold[223:402,310:407]\n",
    "    count=cv2.countNonZero(image1)\n",
    "    spacecounter=0\n",
    "    \n",
    "#     making a threshold for the parking lot(vacant,occupied,wrong)\n",
    "    if count>3300:\n",
    "        color=(255,0,0)\n",
    "        thickness=2\n",
    "        cvzone.putTextRect(image,str('occupied'),(310,223),scale=1,thickness=2,offset=0)\n",
    "    elif count<500:\n",
    "        color=(0,255,0)\n",
    "        thickness=2\n",
    "        cvzone.putTextRect(image,str('vacant'),(310,223),scale=1,thickness=2,offset=0)\n",
    "        spacecounter+=1\n",
    "    elif count>=1500 or count<=2500:\n",
    "        color=(0,0,255)\n",
    "        thickness=2\n",
    "        var=True\n",
    "        \n",
    "    image2=imgthreshold[215:390,477:600]\n",
    "    count2=cv2.countNonZero(image2)\n",
    "\n",
    "    if count2>3300:\n",
    "        color1=(255,0,0)\n",
    "        thickness=2\n",
    "        cvzone.putTextRect(image,str('occupied'),(477,215),scale=1,thickness=2,offset=0)\n",
    "    elif count2<500:\n",
    "        color1=(0,255,0)\n",
    "        thickness=2\n",
    "        spacecounter+=1\n",
    "        cvzone.putTextRect(image,str('vacant'),(477,215),scale=1,thickness=2,offset=0)\n",
    "    elif count2>=1500 or count2<=2500:\n",
    "        color1=(0,0,255)\n",
    "        thickness=2\n",
    "        var1=True\n",
    "#         condition for wrong parking if occurs and detection of number of the car\n",
    "    if var==True and var1==True:\n",
    "        cvzone.putTextRect(image,str(\"Wrong\"),(477,215),scale=1,thickness=2,offset=0)\n",
    "        cvzone.putTextRect(image,str(\"Wrong\"),(310,223),scale=1,thickness=2,offset=0)\n",
    "        if count2>1500 or count<2200:\n",
    "            cvzone.putTextRect(image,str('LE 4377'),(300,325),scale=1,thickness=2,offset=10)\n",
    "#         image = cv2.putText(image, 'LE 4377', (280,327), cv2.FONT_HERSHEY_COMPLEX, \n",
    "#                    1, (255,0,0), 2, cv2.LINE_AA)\n",
    "        var!=var\n",
    "        var1!=var1\n",
    "        cascade=cv2.CascadeClassifier('cascade_ALRP.xml')\n",
    "        states={'L':'Lahore','ICT':'islamabad','R':'Rawalpindi'}\n",
    "        img=cv2.imread('Capture1.png')\n",
    "        img=cv2.resize(img,(700,600))\n",
    "        gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        nplate=cascade.detectMultiScale(gray,1.1,4)\n",
    "#         print(nplate)\n",
    "        for (x,y,w,h) in nplate:\n",
    "            plate=img[y:y+h,x:x+w,:]\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(51,51,255),2)\n",
    "            cvzone.putTextRect(img,str('LA 4377'),(306,306),scale=0.7,thickness=2,offset=2)\n",
    "    image3=imgthreshold[218:429,666:951]\n",
    "    count3=cv2.countNonZero(image3) \n",
    "    if count3>3300:\n",
    "        color2=(255,0,0)\n",
    "        thickness=2\n",
    "        cvzone.putTextRect(image3,str('occupied'),(477,215),scale=1,thickness=2,offset=0)\n",
    "    elif count3<2000:\n",
    "        color2=(0,255,0)\n",
    "        thickness=2\n",
    "        cvzone.putTextRect(image,str('vacant'),(666,218),scale=1,thickness=2,offset=0)\n",
    "        spacecounter+=1\n",
    "    elif count3>=1500 or count3<=2500:\n",
    "        color2=(0,0,255)\n",
    "        thickness=2\n",
    "        var2=True\n",
    "    cvzone.putTextRect(image,f'Available parking:{spacecounter}/{3}',(100,100),scale=1.5,thickness=2,offset=10,colorR=(0,200,0))\n",
    "    cv2.line(image, (310, 223), (207, 401), color,thickness)\n",
    "    cv2.line(image, (207, 401), (407, 402), color,thickness)\n",
    "    cv2.line(image, (407, 402), (446, 222), color,thickness)\n",
    "    cv2.line(image, (446, 222), (310, 223), color,thickness)\n",
    "\n",
    "    \n",
    "    cv2.line(image, (477, 215), (444, 397), color1,thickness)\n",
    "    cv2.line(image, (444, 397),(664, 403), color1,thickness)\n",
    "    cv2.line(image, (664, 403), (620, 215), color1,thickness)\n",
    "    cv2.line(image, (620, 215), (477, 215), color1,thickness)\n",
    "    \n",
    "    \n",
    "    cv2.line(image, (675, 227), (715, 399), color2,thickness)\n",
    "    \n",
    "    cv2.line(image, (715, 399), (925, 403), color2,thickness)\n",
    "    cv2.line(image, (925, 403), (824, 225), color2,thickness)\n",
    "    cv2.line(image, (824, 225), (675, 227), color2,thickness)\n",
    "\n",
    "    \n",
    "#     ractangle on threshold image\n",
    "    cv2.line(imgthreshold, (310, 223), (207, 401), (255,0,255),2)\n",
    "    cv2.line(imgthreshold, (207, 401), (407, 402), (255,0,255),2)\n",
    "    cv2.line(imgthreshold, (407, 402), (446, 222), (255,0,255),2)\n",
    "    \n",
    "    cv2.line(imgthreshold, (446, 222), (310, 223), (255,0,255),2)\n",
    "    \n",
    "    cv2.line(imgthreshold, (477, 215), (444, 397), (255,0,255),2)\n",
    "    cv2.line(imgthreshold, (444, 397),(664, 403), (255,0,255),2)\n",
    "    cv2.line(imgthreshold, (664, 403), (620, 215), (255,0,255),2)\n",
    "    cv2.line(imgthreshold, (620, 215), (477, 215), (255,0,255),2)\n",
    "    \n",
    "    cv2.line(imgthreshold, (675, 227), (715, 399), (255,0,255),2)\n",
    "    cv2.line(imgthreshold, (715, 399), (925, 403), (255,0,255),2)\n",
    "    cv2.line(imgthreshold, (925, 403), (824, 225), (255,0,255),2)\n",
    "    cv2.line(imgthreshold, (824, 225), (675, 227), (255,0,255),2)\n",
    "    \n",
    "#     median image\n",
    "    cv2.line(imgMedian, (310, 223), (207, 401), (255,0,255),2)\n",
    "    cv2.line(imgMedian, (207, 401), (407, 402), (255,0,255),2)\n",
    "    cv2.line(imgMedian, (407, 402), (446, 222), (255,0,255),2)\n",
    "    cv2.line(imgMedian, (446, 222), (310, 223), (255,0,255),2)\n",
    "    \n",
    "    cv2.line(imgMedian, (477, 215), (444, 397), (255,0,255),2)\n",
    "    cv2.line(imgMedian, (444, 397),(664, 403), (255,0,255),2)\n",
    "    cv2.line(imgMedian, (664, 403), (640, 215), (255,0,255),2)\n",
    "    cv2.line(imgMedian, (640, 215), (477, 215), (255,0,255),2)\n",
    "    \n",
    "    cv2.line(imgMedian, (675, 227), (715, 399), (255,0,255),2)\n",
    "    cv2.line(imgMedian, (715, 399), (925, 403), (255,0,255),2)\n",
    "    cv2.line(imgMedian, (925, 403), (824, 225), (255,0,255),2)\n",
    "    cv2.line(imgMedian, (824, 225), (675, 227), (255,0,255),2)\n",
    "\n",
    "    cv2.imshow('orignal', image)\n",
    "    cv2.imshow(str(215*477),image1)\n",
    "    cv2.imshow(str(223*310),image2)\n",
    "    cv2.imshow('threshold', imgthreshold)\n",
    "\n",
    "    cv2.imshow('medianimage',imgMedian)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('y'):\n",
    "        break\n",
    "    \n",
    "video1.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e720a4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
